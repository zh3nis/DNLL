{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7531278",
   "metadata": {},
   "source": [
    "# CIFAR-100 Classification with an MDA Head\n",
    "This notebook trains a small convolutional encoder with a mixture discriminant analysis (MDA) head\n",
    "on CIFAR-100, then plots train/test accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb73f4a",
   "metadata": {},
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from dnll import MDAHead, EM_DNLLLoss, DNLLLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae66dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device =', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a6f20",
   "metadata": {},
   "source": [
    "### Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73800851",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.5071, 0.4867, 0.4408)\n",
    "std = (0.2675, 0.2565, 0.2761)\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR100(root='./data', train=True, transform=train_tfm, download=True)\n",
    "test_ds  = datasets.CIFAR100(root='./data', train=False, transform=test_tfm, download=True)\n",
    "train_ld = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=4, pin_memory=pin_memory)\n",
    "test_ld  = DataLoader(test_ds,  batch_size=1024, shuffle=False, num_workers=4, pin_memory=pin_memory)\n",
    "len(train_ds), len(test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913fe1a",
   "metadata": {},
   "source": [
    "### Model: encoder + MDA head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0462e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.proj = nn.Linear(256, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.proj(x)\n",
    "\n",
    "class DeepMDA(nn.Module):\n",
    "    def __init__(self, C, D, K):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(D)\n",
    "        self.head = MDAHead(C, D, K)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.head(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3538f0",
   "metadata": {},
   "source": [
    "### Train & Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    ok = tot = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        ok += (logits.argmax(1) == y).sum().item()\n",
    "        tot += y.size(0)\n",
    "    return ok / tot\n",
    "\n",
    "\n",
    "model = DeepMDA(C=100, D=99, K=2).to(device)\n",
    "#opt = torch.optim.Adam([\n",
    "#    {\"params\": model.encoder.parameters(), \"lr\": 1e-3},\n",
    "#    {\"params\": model.head.parameters(), \"lr\": 1e-4},\n",
    "#])\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_fn = EM_DNLLLoss()\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    loss_sum = acc_sum = n_sum = 0\n",
    "    for x, y in train_ld:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        z = model.encoder(x)\n",
    "        loss = loss_fn(model.head, z, y)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        with torch.no_grad():\n",
    "            logits = model.head(z)\n",
    "            pred = logits.argmax(1)\n",
    "            acc_sum += (pred == y).sum().item()\n",
    "            n_sum += y.size(0)\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "    tr_acc = acc_sum / n_sum\n",
    "    te_acc = evaluate(model, test_ld)\n",
    "    train_acc.append(tr_acc)\n",
    "    test_acc.append(te_acc)\n",
    "    print(f'[MDA {epoch:02d}] train loss={loss_sum/n_sum:.4f} acc={tr_acc:.4f} | test acc={te_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb925509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "plt.figure(figsize=(6.5, 4.5))\n",
    "plt.plot(epochs, train_acc, label='Train acc', linewidth=2)\n",
    "plt.plot(epochs, test_acc, label='Test acc', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MDA CIFAR-100 Accuracy')\n",
    "plt.legend(frameon=False)\n",
    "plt.grid(True, linewidth=0.4, alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
